{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - Run this cell only if you are using Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.14 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (3.7.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (1.16.4)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (1.14.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (1.11.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (0.3.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (0.8.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (1.10.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (1.0.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (0.1.7)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (1.11.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (0.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (0.31.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==1.14) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow==1.14) (41.5.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.1)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.8.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting shap==0.32.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/43/08f152a59a1d60f0328b476bdd58c791498989981ab9c6d595ec5448a86a/shap-0.32.1.tar.gz (259kB)\n",
      "\u001b[K    100% |████████████████████████████████| 266kB 28.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from shap==0.32.1) (1.16.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from shap==0.32.1) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from shap==0.32.1) (0.21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from shap==0.32.1) (0.24.2)\n",
      "Collecting tqdm>4.25.0 (from shap==0.32.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c9/7fc20feac72e79032a7c8138fd0d395dc6d8812b5b9edf53c3afd0b31017/tqdm-4.41.1-py2.py3-none-any.whl (56kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 27.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-learn->shap==0.32.1) (0.13.2)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas->shap==0.32.1) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas->shap==0.32.1) (2.7.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas->shap==0.32.1) (1.11.0)\n",
      "Building wheels for collected packages: shap\n",
      "  Running setup.py bdist_wheel for shap ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/8e/b2/50/8fadb5a59789cb5bdeb01b800223be540651ae92915172050b\n",
      "Successfully built shap\n",
      "Installing collected packages: tqdm, shap\n",
      "Successfully installed shap-0.32.1 tqdm-4.41.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting spacy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.4MB 4.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/b5/3e1714ebda8fd7c5859f9b216e381adc0a38b962f071568fd00d67e1b1ca/cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 55.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting thinc<7.4.0,>=7.3.0 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.2MB 21.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy) (1.16.4)\n",
      "Collecting catalogue<1.1.0,>=0.0.7 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/f9/9a5658e2f56932e41eb264941f9a2cb7f3ce41a80cb36b2af6ab78e2f8af/catalogue-1.0.0-py2.py3-none-any.whl\n",
      "Collecting plac<1.2.0,>=0.9.6 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\n",
      "Collecting wasabi<1.1.0,>=0.4.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/21/e1/e4e7b754e6be3a79c400eb766fb34924a6d278c43bb828f94233e0124a21/wasabi-0.6.0-py3-none-any.whl\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/e6/63f160a4fdf0e875d16b28f972083606d8d54f56cd30cb8929f9a1ee700e/murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy) (2.20.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy) (41.5.1)\n",
      "Collecting srsly<1.1.0,>=0.1.0 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/96/3350d3fa0cfa2b2ff341113d60b5bfe0ab8dd0e6b6b2c8b12157b4eb3000/srsly-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (185kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 56.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.5.0,>=0.4.0 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.7MB 12.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.41.1)\n",
      "Collecting importlib-metadata>=0.20; python_version < \"3.8\" (from catalogue<1.1.0,>=0.0.7->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/31/74dcb59a601b95fce3b0334e8fc9db758f78e43075f22aeb3677dfb19f4c/importlib_metadata-1.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.23)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/74/3d/1ee25a26411ba0401b43c6376d2316a71addcc72ef8690b101b4ea56d76a/zipp-0.6.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: more-itertools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (4.1.0)\n",
      "Requirement already satisfied: six<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from more-itertools->zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (1.11.0)\n",
      "Installing collected packages: cymem, murmurhash, preshed, wasabi, plac, srsly, blis, thinc, zipp, importlib-metadata, catalogue, spacy\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 cymem-2.0.3 importlib-metadata-1.4.0 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 spacy-2.2.3 srsly-1.0.1 thinc-7.3.1 wasabi-0.6.0 zipp-0.6.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.0MB 53.1MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.20.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.16.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (41.5.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.23)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.9.11)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.1.0)\n",
      "Requirement already satisfied: six<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from more-itertools->zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.11.0)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Running setup.py install for en-core-web-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed en-core-web-sm-2.2.5\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install 'tensorflow==1.14'\n",
    "!pip install 'shap==0.32.1'\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "import collections \n",
    "import itertools\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import shap\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import LSTM, Embedding, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and Process Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data'\n",
    "fname = 'amazon_reviews_us_Musical_Instruments_v1_00.tsv'\n",
    "\n",
    "os.path.join(path, fname)\n",
    "df = pd.read_csv(os.path.join(path, fname), sep = '\\t', error_bad_lines = False, warn_bad_lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We started with 123284 unique ids\n",
      "After cleansing we are left with 1105 products\n",
      "Total dataset size is now 286055 rows\n"
     ]
    }
   ],
   "source": [
    "# Find the products with less than 100 reviews\n",
    "print(\"We started with {} unique ids\".format(len(df['product_id'].unique())))\n",
    "reviews_threshold = 100\n",
    "pdist = df[['product_id', 'review_id']].groupby('product_id', as_index = False).count()\n",
    "prods_to_keep = pdist[pdist['review_id'] > reviews_threshold]['product_id'].unique()\n",
    "\n",
    "df = df[df['product_id'].isin(prods_to_keep)]\n",
    "print(\"After cleansing we are left with {} products\".format(len(df['product_id'].unique())))\n",
    "print(\"Total dataset size is now {} rows\".format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and Shap Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After rebuilding the model architecture we load pre-trained weights. We then calculate shap values for a number of product reviews and save locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "maxlen = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(max_words, embedding_dim, input_length):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, embedding_dim, input_length=input_length))\n",
    "    model.add(LSTM(100, return_sequences = False))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          8227900   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 8,311,565\n",
      "Trainable params: 8,311,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# After training make inference after loading from latest checkpoint\n",
    "\n",
    "max_words = 82279 # This should be fixed\n",
    "\n",
    "inf_model = lstm_model(max_words, embedding_dim, maxlen)\n",
    "\n",
    "# load weights\n",
    "inf_model.load_weights(\"Models/weights-lstm-10.hdf5\")\n",
    "\n",
    "# Compile model (required to make predictions)\n",
    "inf_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Load vectors\n",
    "x_train = np.load(os.path.join(path, 'x_train.npy'))\n",
    "y_train = np.load(os.path.join(path, 'y_train.npy'))\n",
    "ids_train = np.load(os.path.join(path, 'ids_train.npy'))\n",
    "prod_ids_train = np.load(os.path.join(path, 'prod_ids_train.npy'))\n",
    "\n",
    "x_test = np.load(os.path.join(path, 'x_test.npy'))\n",
    "y_test = np.load(os.path.join(path, 'y_test.npy'))\n",
    "ids_test = np.load(os.path.join(path, 'ids_test.npy'))\n",
    "prod_ids_test = np.load(os.path.join(path, 'prod_ids_test.npy'))\n",
    "\n",
    "# Load and unpickle tokenizer\n",
    "with open(os.path.join(path, 'dictionary.pickle'), \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Read in contractions, needed to clean up text\n",
    "with open(os.path.join(path, 'contractions.pickle'), \"rb\") as f:\n",
    "    contractions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the first 100 training examples as our background dataset to integrate over\n",
    "explainer = shap.DeepExplainer(inf_model, x_train[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Products with more than 100 reviews, then find which of those products are in the test products\n",
    "\n",
    "prods = df[['product_id', 'customer_id']].groupby('product_id').count().reset_index()\n",
    "prods = prods[prods['product_id'].isin(prod_ids_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B0002FO9QY\n",
      "This is a Epiphone 335 Hardshell Guitar Case,\n",
      "There is a total of 111 reviews\n",
      "Average star rating is 4.58\n",
      "already calculated\n"
     ]
    }
   ],
   "source": [
    "for i in prods[prods['customer_id'] > 100]['product_id']:\n",
    "    \n",
    "    sample_id = np.random.choice(list(set(prod_ids_test)))\n",
    "    print(sample_id)\n",
    "    \n",
    "\n",
    "    # Find the indices of the product reviews \n",
    "    indices_samp = [idx if i == sample_id else -1 for idx, i in enumerate(prod_ids_test)]\n",
    "    samp_indices = np.array(list(filter(lambda x: x != -1, indices_samp)))\n",
    "\n",
    "    # Fetch the ids for this product \n",
    "    samp_ids = ids_test[samp_indices]\n",
    "\n",
    "    # Now subset the main dataframe for these reviews\n",
    "    sub = df[df['review_id'].isin(samp_ids)]\n",
    "\n",
    "    print('This is a {}'.format(sub.iloc[0]['product_title']))\n",
    "    print('There is a total of {} reviews'.format(len(sub)))\n",
    "    print('Average star rating is {}'.format(round(np.mean(sub['star_rating']),2)))\n",
    "    \n",
    "    # Check if prod has already been calculated\n",
    "    files = os.listdir('Shaps')\n",
    "    if sample_id in [x.split('_')[1].split('.')[0] for x in files]:\n",
    "        print('already calculated')\n",
    "        pass\n",
    "    else:\n",
    "        # Calculate Shap Values\n",
    "        shap_values = explainer.shap_values(x_test[samp_indices])\n",
    "        np.save('Shaps/shaps_{}.npy'.format(sample_id), shap_values)\n",
    "        \n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Reviews Data\n",
    "\n",
    "We create summary reviews using pre-calculated shap values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetize_reviews(reviews, words_df, reviews_df, pos_sentiment):\n",
    "    \"\"\"Synthetize Review based on shap values\n",
    "\n",
    "    Arguments:\n",
    "      reviews: pandas df, \n",
    "          candidate reviews to look for sentences\n",
    "      words_df: pandas df,\n",
    "          dataframe with shaps values for \n",
    "          each word in a review\n",
    "      reviews_df: pandas df,\n",
    "          dataframe of reviews\n",
    "      pos_sentiment: boolean \n",
    "          raw reviews dataframe\n",
    "  \"\"\"\n",
    "    \n",
    "    sentences_for_summary = []\n",
    "    review_ids = []\n",
    "    \n",
    "    for word in reviews['word']:\n",
    "        \n",
    "        if pos_sentiment:\n",
    "            temp = words_df[(words_df['word'] == word) & \n",
    "                      (words_df['shap'] > 0) & \n",
    "                      (words_df['star_rating'] > 3) & \n",
    "                      (words_df['review_len'] > 10)]\n",
    "        else:\n",
    "            temp = words_df[(words_df['word'] == word) & \n",
    "                      (words_df['shap'] < 0) & \n",
    "                      (words_df['star_rating'] <= 3) & \n",
    "                      (words_df['review_len'] > 10)]\n",
    "        \n",
    "        try:\n",
    "            # Find Review with the highest absolute shap associated to that word\n",
    "            temp = temp.sort_values(by = 'absolute_shap', ascending = False)\n",
    "            ts = temp.iloc[0].samp_id\n",
    "\n",
    "            # Extract single review\n",
    "            ind_review = reviews_df[reviews_df['review_id'] == ts].iloc[0]\n",
    "            ind_review = ind_review['review_body']\n",
    "            review_ids.append(ts)\n",
    "\n",
    "            # Split the selected review into sentences\n",
    "            nlp = en_core_web_sm.load()\n",
    "            sentences = list(nlp(ind_review).sents)\n",
    "\n",
    "            # Split the review into sentences and take the first sentence where the word appears\n",
    "            target_word_sents = []\n",
    "\n",
    "            for sent in sentences:\n",
    "                if str(sent).lower().find(word) >= 0:\n",
    "                    target_word_sents.append(sent)\n",
    "\n",
    "            # Check that the target word is long enough, otherwise take the first sentence in the review\n",
    "            length_threshold = 5\n",
    "            if len(str(target_word_sents[0]).split(\" \")) <= 5:\n",
    "                sentences_for_summary.append(sentences[0])\n",
    "            else:\n",
    "                sentences_for_summary.append(target_word_sents[0])\n",
    "\n",
    "\n",
    "        except IndexError:\n",
    "            pass\n",
    "        \n",
    "    return sentences_for_summary, review_ids\n",
    "\n",
    "def benchmark_model(word_scores, sumdf, suprev, df):\n",
    "    \"\"\"Benchmark model to summarize reviews using a\n",
    "    word frequencies algorithm\n",
    "\n",
    "    Arguments:\n",
    "      word_scores: pandas df, \n",
    "          dataframe of word scores\n",
    "      sumdf: pandas df,\n",
    "          dataframe with shaps values for \n",
    "          each word in a review\n",
    "      suprev: pandas df,\n",
    "          reference super review\n",
    "      df: pandas df\n",
    "          raw reviews dataframe\n",
    "  \"\"\"\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Positive Reviews\n",
    "    pos_ = sumdf[sumdf['star_rating'] > 3]\n",
    "    pos_freq = pd.DataFrame(pos_['word'].value_counts()).reset_index()\n",
    "    pos_freq.columns = ['word', 'frequency']\n",
    "    pos_freq = pd.merge(pos_freq, word_scores[['word', 'tag']], on = 'word', how = 'left')\n",
    "    pos_freq = pos_freq[pos_freq['tag'].isin(['NOUN', 'PROPN'])\n",
    "                       ].head(len(suprev[suprev['type'] == 'positives']))\n",
    "\n",
    "    # Negative Reviews\n",
    "    neg_ = sumdf[sumdf['star_rating'] <= 3]\n",
    "    neg_freq = pd.DataFrame(neg_['word'].value_counts()).reset_index()\n",
    "    neg_freq.columns = ['word', 'frequency']\n",
    "    neg_freq = pd.merge(neg_freq, word_scores[['word', 'tag']], on = 'word', how = 'left')\n",
    "    neg_freq = neg_freq[neg_freq['tag'].isin(['NOUN', 'PROPN'])\n",
    "                       ].head(len(suprev[suprev['type'] == 'negatives']))\n",
    "\n",
    "    super_review = []\n",
    "    review_ids = []\n",
    "\n",
    "    for w in pos_freq['word']:\n",
    "\n",
    "        temp = sumdf[(sumdf['word'] == w) & \n",
    "                     (sumdf['star_rating'] > 3)]['samp_id'].sample().iloc[0]\n",
    "\n",
    "        # Extract single review\n",
    "        ind_review = df[df['review_id'] == temp].iloc[0]\n",
    "        ind_review = ind_review['review_body']\n",
    "\n",
    "        # Split the selected review into sentences\n",
    "        nlp = en_core_web_sm.load()\n",
    "        sentences = list(nlp(ind_review).sents)\n",
    "\n",
    "        # Split the review into sentences and take the first sentence where the word appears\n",
    "        target_word_sents = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            if str(sent).lower().find(w) >= 0:\n",
    "                target_word_sents.append(sent)\n",
    "\n",
    "        super_review.append(target_word_sents[0])\n",
    "        review_ids.append(temp)\n",
    "\n",
    "\n",
    "    for w in neg_freq['word']:\n",
    "\n",
    "        temp = sumdf[(sumdf['word'] == w) & \n",
    "                     (sumdf['star_rating'] <= 3)]['samp_id'].sample().iloc[0]\n",
    "\n",
    "        # Extract single review\n",
    "        ind_review = df[df['review_id'] == temp].iloc[0]\n",
    "        ind_review = ind_review['review_body']\n",
    "\n",
    "        # Split the selected review into sentences\n",
    "        nlp = en_core_web_sm.load()\n",
    "        sentences = list(nlp(ind_review).sents)\n",
    "\n",
    "        # Split the review into sentences and take the first sentence where the word appears\n",
    "        target_word_sents = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            if str(sent).lower().find(w) >= 0:\n",
    "                target_word_sents.append(sent)\n",
    "\n",
    "        super_review.append(target_word_sents[0])\n",
    "        review_ids.append(temp)\n",
    "        \n",
    "    return super_review, review_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate super reviews using pre-calculated shap values\n",
    "\n",
    "super_review_dfs = []\n",
    "evals = []\n",
    "prod_ids = []\n",
    "n_words = 10\n",
    "\n",
    "i = 0\n",
    "\n",
    "for sample_file in os.listdir('Shaps'):\n",
    "\n",
    "    print(sample_file)\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    # Find product id\n",
    "    sample_id = sample_file.split('_')[1].split('.')[0]\n",
    "    prod_ids.append(sample_id)\n",
    "\n",
    "    # Find the indices of the product reviews\n",
    "    indices_samp = [idx if i == sample_id else -1 for idx, i in enumerate(prod_ids_test)]\n",
    "    samp_indices = np.array(list(filter(lambda x: x != -1, indices_samp)))\n",
    "    samp_ids = ids_test[samp_indices]\n",
    "\n",
    "    # Subset the main dataframe for these reviews\n",
    "    sub = df[df['review_id'].isin(samp_ids)]\n",
    "\n",
    "    print('This is a {}'.format(sub.iloc[0]['product_title']))\n",
    "    print('There is a total of {} reviews'.format(len(sub)))\n",
    "    print('Average star rating is {}'.format(round(np.mean(sub['star_rating']),2)))\n",
    "\n",
    "    # Load shap values\n",
    "    shap_values = np.load(os.path.join('Shaps', sample_file))\n",
    "\n",
    "    #----------------------------------------------------------------#\n",
    "    # Create Dataframe at word and review level                      #\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    # Crea a daframe of shaps associated to each word\n",
    "    flat_shap = np.ravel(shap_values)\n",
    "    flat_word_idx = np.ravel(x_test[samp_indices])\n",
    "    flat_ids = np.ravel([np.repeat(x, maxlen) for x in samp_ids])\n",
    "\n",
    "    sumdf = pd.DataFrame({'shap': flat_shap,\n",
    "                          'absolute_shap': np.abs(flat_shap),\n",
    "                          'word_index': flat_word_idx,\n",
    "                          'samp_id': flat_ids\n",
    "                          })\n",
    "\n",
    "    # We are also interested in the weight each individual word has compared to the total shap value.\n",
    "    # For this we aggregate by sample ID and sum the total shap\n",
    "    totshap = sumdf[['absolute_shap', 'samp_id']].groupby('samp_id').sum().reset_index()\n",
    "    totshap.rename(columns = {'absolute_shap': 'tot_abs_shap'}, inplace = True)\n",
    "\n",
    "    sumdf = pd.merge(sumdf, totshap, on = 'samp_id', how = 'left')\n",
    "    sumdf['relative_abs_shap'] = sumdf['absolute_shap']/sumdf['tot_abs_shap']\n",
    "\n",
    "    # Do the same to find the length of a sequence\n",
    "    sumdf['is_word'] = sumdf['word_index']/sumdf['word_index']\n",
    "    lens = sumdf[['samp_id', 'is_word']].groupby('samp_id').sum().reset_index()\n",
    "    lens.rename(columns = {'is_word': 'review_len'}, inplace = True)\n",
    "    sumdf = pd.merge(sumdf, lens, on = 'samp_id', how = 'left')\n",
    "\n",
    "    # Remove 0 word index\n",
    "    sumdf = sumdf[sumdf['word_index'] != 0]\n",
    "    print(\"After removing NA we are left with {} words\".format(len(sumdf)))\n",
    "\n",
    "    # Find the word associated to each word index\n",
    "    sumdf['word'] = [tokenizer.index_word[x] for x in sumdf['word_index']]\n",
    "\n",
    "    # Create a feature which tell us if shap value is positive or negative\n",
    "    sumdf['pos_shap'] = sumdf['shap'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    # Join star rating and helpful votes, which will be useful further ahead\n",
    "    sumdf = pd.merge(sumdf, \n",
    "             df[['review_id', 'star_rating', 'helpful_votes']].rename(columns = {'review_id': 'samp_id'}),\n",
    "             on = 'samp_id',\n",
    "             how = 'left')\n",
    "\n",
    "    #----------------------------------------------------------------#\n",
    "    # Create Word Level DataFrame                                    #\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    # For each word find the average relative score. This will help finding the heavy weight words\n",
    "    cols = ['word', 'relative_abs_shap', 'pos_shap']\n",
    "    word_scores = sumdf[cols].groupby('word').agg({'relative_abs_shap': [np.mean, len],\n",
    "                                                   'pos_shap': np.sum})\n",
    "    word_scores = word_scores.reset_index()\n",
    "    word_scores.columns = ['word', 'mean_relative_abs_shap', 'frequency', 'frequency_pos_shap']\n",
    "\n",
    "    # We assign a score to each word, weighting by the log of the word frequency\n",
    "    word_scores['score'] = word_scores['mean_relative_abs_shap'] * np.log(word_scores['frequency'])\n",
    "    word_scores['score'] = word_scores['mean_relative_abs_shap'] * word_scores['frequency']\n",
    "\n",
    "    # We find the ratio of word associated with a positive score (positive sentiment) on total word freq\n",
    "    word_scores['pos_sentiment_score'] = word_scores['frequency_pos_shap'] / word_scores['frequency']\n",
    "    word_scores = word_scores.sort_values(by = 'score', ascending = False)\n",
    "\n",
    "    # Using nltk assign a tag to each word \n",
    "    nlp = en_core_web_sm.load()\n",
    "    word_scores['tag'] = [[token.pos_ for token in nlp(x)][0] for x in word_scores['word']]\n",
    "\n",
    "    #----------------------------------------------------------------#\n",
    "    # Find Top n positive sentiment words and Top n negative words   #\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    positives = word_scores[(word_scores['pos_sentiment_score'] > 0.7) &\n",
    "                        (word_scores['tag'].isin(['NOUN', 'PROPN']))\n",
    "                        ].head(n_words)\n",
    "\n",
    "    negatives = word_scores[(word_scores['pos_sentiment_score'] < 0.3) &\n",
    "                        (word_scores['tag'].isin(['NOUN', 'PROPN']))\n",
    "                        ].head(n_words)\n",
    "\n",
    "    #----------------------------------------------------------------#\n",
    "    # Find Top n positive sentiment words and Top n negative words   #\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    synth_pos = synthetize_reviews(positives, sumdf, df, pos_sentiment=True)\n",
    "    synth_neg = synthetize_reviews(negatives, sumdf, df, pos_sentiment=False)\n",
    "\n",
    "    #----------------------------------------------------------------#\n",
    "    # Find Top n positive sentiment words and Top n negative words   #\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    pos_df = pd.DataFrame({'sentences': synth_pos[0], 'review_ids': synth_pos[1], 'type': 'positives'})\n",
    "    neg_df = pd.DataFrame({'sentences': synth_neg[0], 'review_ids': synth_neg[1], 'type': 'negatives'})\n",
    "\n",
    "    suprev = pd.concat([pos_df, neg_df])\n",
    "    suprev['sentences'] = suprev['sentences'].astype('str')\n",
    "    suprev.drop_duplicates(inplace = True)\n",
    "    suprev['product_id'] = sample_id\n",
    "\n",
    "    #----------------------------------------------------------------#\n",
    "    # Benchmark Model                                                #\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    super_review, review_ids = benchmark_model(word_scores, sumdf, suprev, df)\n",
    "    super_review_bench = pd.DataFrame({'sentences': super_review, 'review_ids': review_ids, 'type': 'benchmark'})\n",
    "    super_review_bench['sentences'] = super_review_bench['sentences'].astype('str')\n",
    "    super_review_bench.drop_duplicates(inplace = True)\n",
    "    super_review_bench['product_id'] = sample_id\n",
    "\n",
    "    #----------------------------------------------------------------#\n",
    "    # Evaluation                                                     #\n",
    "    #----------------------------------------------------------------#\n",
    "\n",
    "    suprev_log_votes = np.mean(np.log1p(\n",
    "        df[df['review_id'].isin(suprev['review_ids'].unique())]['total_votes']))\n",
    "\n",
    "    naive_log_votes = np.mean(np.log1p(\n",
    "        df[df['review_id'].isin(review_ids)]['total_votes']))\n",
    "\n",
    "    print(\"Shap log votes: {}\".format(suprev_log_votes))\n",
    "    print(\"Naive log votes: {}\".format(naive_log_votes))\n",
    "\n",
    "    # Append Final Result\n",
    "    super_review_dfs.append(pd.concat([suprev, super_review_bench]))\n",
    "    evals.append((suprev_log_votes, naive_log_votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of scores, where we can compare shap and benchmark model.\n",
    "\n",
    "evals_df =  pd.DataFrame({'shap': [x[0] for x in evals], \n",
    "              'naive':[x[1] for x in evals],\n",
    "              'product_id': prod_ids\n",
    "             })\n",
    "\n",
    "\n",
    "evals_df = pd.merge(evals_df,\n",
    "         df[['product_id', 'customer_id']].groupby('product_id').count().reset_index(),\n",
    "         on = 'product_id',\n",
    "         how = 'left'\n",
    "        )\n",
    "\n",
    "evals_df['delta'] = evals_df['shap'] - evals_df['naive']\n",
    "evals_df = evals_df.sort_values(by = 'customer_id', ascending = False)\n",
    "evals_df.columns = ['shap', 'naive', 'product_id', 'reviews', 'delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Evaluation DataFrame\n",
    "evals_df.to_csv('Data/evals.csv', index = False)\n",
    "evals_df = pd.read_csv('Data/evals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shap Model Log Votes:  0.6784162055497084\n",
      "Benchmark Model Log Votes:  0.8652754620214622\n",
      "Shap Model Tot Reviews:  59\n",
      "Shap Model Tot Reviews:  59\n"
     ]
    }
   ],
   "source": [
    "# Get average log votes score for shap vs benchmark model\n",
    "\n",
    "tot_reviews = 100\n",
    "\n",
    "print(\"Shap Model Log Votes: \", np.mean(evals_df[evals_df['reviews'] > tot_reviews]['shap']))\n",
    "print(\"Benchmark Model Log Votes: \", np.mean(evals_df[evals_df['reviews'] > tot_reviews]['naive']))\n",
    "\n",
    "print(\"Shap Model Tot Reviews: \", len(evals_df[evals_df['reviews'] > tot_reviews]['shap']))\n",
    "print(\"Shap Model Tot Reviews: \", len(evals_df[evals_df['reviews'] > tot_reviews]['naive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.6828477561316464, pvalue=0.00836641994078426)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if observed mean log votes difference is statistically significant\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "ttest_ind(evals_df[evals_df['reviews'] > tot_reviews]['shap'], \n",
    "          evals_df[evals_df['reviews'] > tot_reviews]['naive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 0.7088230988097073)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot how the delta in score between the two models relates to number of reviews\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "\n",
    "plt.scatter(evals_df[evals_df['reviews'] < 700]['reviews'], \n",
    "            evals_df[evals_df['reviews'] < 700]['delta'], alpha = 0.5)\n",
    "plt.axhline(0)\n",
    "plt.xlabel('Number of Product Reviews')\n",
    "plt.ylabel('Log Votes Difference')\n",
    "plt.title('Log Votes Difference Between Shap Model and Naive Model')\n",
    "plt.ylim(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset of Super Reviews and save\n",
    "\n",
    "final_reviews_set = pd.concat(super_review_dfs)\n",
    "final_reviews_set.to_csv('Data/super_reviews.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASCAM DR-05EB Portable Digital Recorder\n",
      "------\n",
      "Great Thing, Good Size, Great Microphone Response\n",
      "But when I use 8G and 16G card to expand the memory, it shows also 2G.\n",
      "Decent recording quality.\n",
      "The price was big money to me\n",
      "The audio quality is good and the headphones are decent.\n",
      "I had to get help for that, but  would  absolutely recommend for singers and musicians.\n",
      "Works great for the price point with a true stereo recording!\n",
      "Great small audio recorder, Using it for capturing audio on the weddings.\n",
      "Took itnout to test it right away and fell in love with the sound quality it was giving me.\n"
     ]
    }
   ],
   "source": [
    "# Print one sample positive review\n",
    "\n",
    "sample_prod = final_reviews_set['product_id'].sample().iloc[0]\n",
    "sample_prod = 'B0090XX0MS'\n",
    "\n",
    "print(df[df['product_id'] == sample_prod]['product_title'].iloc[0])\n",
    "print(\"------\")\n",
    "\n",
    "revs = final_reviews_set[final_reviews_set['product_id'] == sample_prod]\n",
    "for i in revs[revs['type'] == 'positives']['sentences']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have to return it . . .\n",
      "I play guitar right next to the mic\n",
      "Awful playback quality.\n",
      "There's a tremendous amount of warble, scratchiness, static, distortion, and generally awful noise quality.\n",
      "It sounds good at first and then starts to get all scratchy.\n"
     ]
    }
   ],
   "source": [
    "# Print one sample negative review\n",
    "\n",
    "for i in revs[revs['type'] == 'negatives']['sentences']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I intend to use the recordings in video I was shooting.\n",
      "I use it to record rehearsals and to practice with.\n",
      "Great handy recorder with excellent features and ease of handling.\n",
      "This is a high quality digital recorder perfect for field recordings, live music shows, sound effects and any situation requiring high fidelity sound recording.  \n",
      "Sound quality is excellent!\n",
      "I bought this Digital recorder because of my budget.\n",
      "Voice recordings from the DR-05 can easily be synced with the on-camera voice recordings in Vegas Pro 13, which is a bit of a hassle\n",
      "The audio quality is good and the headphones are decent.\n",
      "Most of the other recorders in this price range only give you a 1gb or nothing.\n",
      "First, the price is right, the recorder has tons of &#34;bang for the buck,&#34; and the recording quality is more than acceptable, but there are several shortcomings.<br /><br />First, my unit did not arrive with the current firmware release installed.  \n",
      "So if you are not familiar with this type of device, reading the manual will be confusing.  \n",
      "With all the positive reviews I can only imagine what the people who love this are actually recording.  \n",
      "The Tascam stopped working 1 month after it's 1 year warranty.<br /><br />I\n"
     ]
    }
   ],
   "source": [
    "# Print one sample benchmark review\n",
    "\n",
    "for i in revs[revs['type'] == 'benchmark']['sentences']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
